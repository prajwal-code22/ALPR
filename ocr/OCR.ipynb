{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B5Z-ogH4HD8K",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B5Z-ogH4HD8K",
    "outputId": "5fda4d0a-e428-4687-d915-b4291ca59b72"
   },
   "outputs": [],
   "source": [
    "!pip install torch torchmetrics torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "037a3d13-c4d7-4fdc-b650-ed4395846e5a",
   "metadata": {
    "id": "037a3d13-c4d7-4fdc-b650-ed4395846e5a"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "from torchmetrics import Accuracy, Recall, Precision\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from image_transformers import train_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "144646ae-a15f-438b-944e-87d4fd6ee6c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "144646ae-a15f-438b-944e-87d4fd6ee6c0",
    "outputId": "274d8b6e-59b2-4763-c2f9-92cfd90182a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Using cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device( 'cuda:0' if torch.cuda.is_available() else 'cpu' )\n",
    "\"Using \"+device.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02399eb6-e780-4661-bf66-df2cc3ebac75",
   "metadata": {
    "id": "02399eb6-e780-4661-bf66-df2cc3ebac75"
   },
   "outputs": [],
   "source": [
    "# Other vars\n",
    "this_training_session_rank = 1\n",
    "\n",
    "# Hyperparams\n",
    "epoch = 10\n",
    "batch_size = 80\n",
    "lr=.01\n",
    "momentum = .9\n",
    "data_to_train_on=100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cb62017-bdbd-4088-87cf-8795281bff3e",
   "metadata": {
    "id": "6cb62017-bdbd-4088-87cf-8795281bff3e"
   },
   "outputs": [],
   "source": [
    "# Loading train and test dataset\n",
    "train_dataset = torchvision.datasets.EMNIST( root=\"./data\", train=True, download=True, transform=train_transforms, split=\"byclass\")\n",
    "test_dataset = torchvision.datasets.EMNIST( root=\"./data\", train=False, download=True, transform=train_transforms, split=\"byclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "SQVjvaYwPQOx",
   "metadata": {
    "id": "SQVjvaYwPQOx"
   },
   "outputs": [],
   "source": [
    "# using only 10,000 datas to train\n",
    "train_dataset = Subset( train_dataset, np.arange(data_to_train_on*(this_training_session_rank-1), data_to_train_on*this_training_session_rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95e9b05e-2808-4619-8ae0-b5058fd23f80",
   "metadata": {
    "id": "95e9b05e-2808-4619-8ae0-b5058fd23f80"
   },
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "train_dataloader = DataLoader( train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader( test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f12e5486-6541-45b9-b2c8-081d47766e7b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f12e5486-6541-45b9-b2c8-081d47766e7b",
    "outputId": "96a44df6-7fb7-460d-b9b5-9fb236ace575"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 64])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data probing\n",
    "# next(iter(train_dataloader))\n",
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c73b0c8f-ee81-424c-b6b3-d33d0bc54145",
   "metadata": {
    "id": "c73b0c8f-ee81-424c-b6b3-d33d0bc54145"
   },
   "outputs": [],
   "source": [
    "class OCRModel(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_conv_net = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),  # --> 32x64x64\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2), # --> 32x32x32\n",
    "\n",
    "            nn.Conv2d(32, 16, kernel_size=3, padding=1), # --> 16x32x32\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),    # --> 16x16x16\n",
    "\n",
    "            nn.Conv2d(16, 10, kernel_size=3 , padding=1), # --> 10x16x16\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2), # --> 10x8x8\n",
    "\n",
    "            nn.Flatten() # --> 10x8x8\n",
    "        )\n",
    "\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(10*8*8, 10),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.BatchNorm1d(10), # Normalizes each batch, that is, tries to make input distribution equal to output distribution.\n",
    "\n",
    "            nn.Linear(10, 10),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Dropout(.3), # Randomly drops some neurons with prob. of 3% reducing chances of overfitting\n",
    "\n",
    "            nn.Linear(10, 5),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(5, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, features):\n",
    "        out = self.image_conv_net(features)\n",
    "        out = self.fc_layer(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "71fef956-3c60-4dca-89ec-2bc7f3e58af4",
   "metadata": {
    "id": "71fef956-3c60-4dca-89ec-2bc7f3e58af4"
   },
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "num_classes = test_dataset.classes.__len__()\n",
    "model = OCRModel(num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "241d2062-4ea0-41ef-9e81-268c54e06fac",
   "metadata": {
    "id": "241d2062-4ea0-41ef-9e81-268c54e06fac"
   },
   "outputs": [],
   "source": [
    "# Loss and optimizers\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "do7pmZD0NNnb",
   "metadata": {
    "id": "do7pmZD0NNnb"
   },
   "outputs": [],
   "source": [
    "# Saving model\n",
    "def save_model(model, final_model: bool=False):\n",
    "    cdt = datetime.now()\n",
    "    now = cdt.strftime(\"%Y-%m-%d_%H_%M_%S\")\n",
    "    saving_dir = f\"intermediate-models\" if not final_model else f\".\"\n",
    "\n",
    "    try:\n",
    "        os.mkdir(\"intermediate-models\")\n",
    "    except:\n",
    "        pass\n",
    "    model_name = f\"model-{now}.pth\" if not final_model else \"model-final.pth\"\n",
    "    torch.save(model.state_dict(), f\"{saving_dir}/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "221d3f94-a19d-492a-a05f-e2bf1b5857c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "221d3f94-a19d-492a-a05f-e2bf1b5857c4",
    "outputId": "90f46742-4348-4e0b-aea6-7207f5860a4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 2.684645977783203 \n",
      "Epoch: 2, Loss: 2.385517695426941 \n",
      "Epoch: 3, Loss: 2.320366182804108 \n",
      "Epoch: 4, Loss: 2.275113148021698 \n",
      "Epoch: 5, Loss: 2.247555594444275 \n",
      "Epoch: 6, Loss: 2.212896706390381 \n",
      "Epoch: 7, Loss: 2.2067477807044984 \n",
      "Epoch: 8, Loss: 2.1937913893699648 \n",
      "Epoch: 9, Loss: 2.1833752579689025 \n",
      "Epoch: 10, Loss: 2.1698438510894777 \n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epoch_loss_store = []\n",
    "for i in range(epoch):\n",
    "    running_loss = .0\n",
    "    for features, labels in train_dataloader:\n",
    "\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass and loss calcuation\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass ans optimizing\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    running_loss /= len(train_dataloader)\n",
    "    print(f\"Epoch: {i+1}, Loss: {running_loss} \")\n",
    "    epoch_loss_store.append(running_loss)\n",
    "    \n",
    "    # Saving model in every 1 epoch\n",
    "    print(\"Saving model...\")\n",
    "    save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2faeb135-0287-419e-ba81-4cfd956437f3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2faeb135-0287-419e-ba81-4cfd956437f3",
    "outputId": "5875b5f2-50a9-4145-aa79-9a913a7afcb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 2667.3486499786377\n",
      "Avg loss: 1.8332293127000947\n",
      "accuracy=tensor(0.4804, device='cuda:0')\n",
      "recall=tensor(0.4804, device='cuda:0')\n",
      "precision=tensor(0.4804, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "\n",
    "all_accuracy = Accuracy(task=\"multiclass\", num_classes=num_classes, average=\"micro\").to(device)\n",
    "all_precision = Precision(task=\"multiclass\", num_classes=num_classes, average=\"micro\").to(device)\n",
    "all_recall = Recall(task=\"multiclass\", num_classes=num_classes, average=\"micro\").to(device)\n",
    "\n",
    "total_loss = .0\n",
    "model.eval() # Changin model to evaluation mode so it doesnot change weignts.\n",
    "with torch.no_grad():\n",
    "\n",
    "    for features, labels in test_dataloader:\n",
    "\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Metrics\n",
    "        all_accuracy(outputs, labels)\n",
    "        all_recall(outputs, labels)\n",
    "        all_precision(outputs, labels)\n",
    "\n",
    "average_loss = total_loss / len(test_dataloader)\n",
    "accuracy = all_accuracy.compute()\n",
    "recall = all_recall.compute()\n",
    "precision = all_precision.compute()\n",
    "\n",
    "print(F\"Total loss: {total_loss}\")\n",
    "print(F\"Avg loss: {average_loss}\")\n",
    "print(F\"{accuracy=}\")\n",
    "print(F\"{recall=}\")\n",
    "print(F\"{precision=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3527f03e-01b1-4e67-a1ca-ee915de5b589",
   "metadata": {
    "id": "3527f03e-01b1-4e67-a1ca-ee915de5b589"
   },
   "outputs": [],
   "source": [
    "# Saving model\n",
    "\n",
    "cdt = datetime.now()\n",
    "now = cdt.strftime(\"%Y-%m-%d_%H_%M_%S\")\n",
    "saving_dir = f\"models/model-{now}\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"models\")\n",
    "except:\n",
    "    pass\n",
    "os.mkdir(saving_dir)\n",
    "\n",
    "with open(f\"{saving_dir}/params.txt\" , \"w\") as f:\n",
    "    f.write(f\"# Hyperparameters \\n\")\n",
    "    f.write(f\"{epoch=}\\n\")\n",
    "    f.write(f\"{batch_size=}\\n\")\n",
    "    f.write(f\"{lr=}\\n\")\n",
    "    f.write(f\"{momentum=}\\n\")\n",
    "    f.write(f\"{data_to_train_on=} datas\\n\\n\")\n",
    "    f.write(f\"{auto_contrast_probability=}\\n\\n\")\n",
    "\n",
    "    f.write(f\"# Metrics \\n\")\n",
    "    f.write(f\"{average_loss=}\\n\")\n",
    "    f.write(f\"{total_loss=}\\n\")\n",
    "    f.write(f\"{recall=}\\n\")\n",
    "    f.write(f\"{precision=}\\n\")\n",
    "    f.write(f\"{accuracy=}\\n\")\n",
    "\n",
    "    f.write(\"# Epoch and loss\\n\")\n",
    "    for loss in epoch_loss_store:\n",
    "      f.write(f\"{loss}\")\n",
    "\n",
    "torch.save(model.state_dict(), f\"./models/model-{now}/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "Zyb8v9IAgcoF",
   "metadata": {
    "id": "Zyb8v9IAgcoF"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  import shutil\n",
    "  from google.colab import files\n",
    "  import zipfile\n",
    "  def zip_folder(folder_path, output_zip_path):\n",
    "\n",
    "    \"\"\"Zips the contents of a folder into a zip file.\n",
    "\n",
    "    Args:\n",
    "        folder_path: The path to the folder to be zipped.\n",
    "        output_zip_path: The path to the output zip file.\n",
    "    \"\"\"\n",
    "\n",
    "    with zipfile.ZipFile(output_zip_path, \"w\") as zip_file:\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                zip_file.write(file_path)\n",
    "  zip_folder(\"/content/models\", \"/content/ts-models.zip\")\n",
    "except:\n",
    "  ..."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
